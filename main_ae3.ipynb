{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40dc5758",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f0c83d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import torch\n",
    "import models\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from dataset_downloader import DatasetDownloader\n",
    "from data_bundler import DataBundler\n",
    "from torch.utils.data import DataLoader\n",
    "from evaluator import Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7461ca3",
   "metadata": {},
   "source": [
    "# Download Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd4fea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_downloader = DatasetDownloader()\n",
    "# dataset_downloader.download_datasets(\"download_paths_2025.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5bf597",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eac7e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hyper_parameters():\n",
    "    with open(\"hyper_parameters.yaml\", 'r') as file:\n",
    "        return yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b475dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters = load_hyper_parameters()\n",
    "\n",
    "#> Acoustic Features\n",
    "acoustic_features = hyper_parameters['acoustic_features']\n",
    "number_of_mels = acoustic_features['number_of_mels']\n",
    "number_of_frames_to_concatenate = acoustic_features['number_of_frames_to_concatenate']\n",
    "frame_size_seconds = acoustic_features['frame_size_seconds']\n",
    "frame_size_samples = acoustic_features['frame_size_samples']\n",
    "hop_size_seconds = acoustic_features['hop_size_seconds']\n",
    "hop_size_samples = acoustic_features['hop_size_samples']\n",
    "\n",
    "\n",
    "#> Dataset Parameters\n",
    "dataset_paremeters = hyper_parameters['dataset_parameters']\n",
    "train_data_inclusion_string = dataset_paremeters['train_data_inclusion_string']\n",
    "test_data_inclusion_string = dataset_paremeters['test_data_inclusion_string']\n",
    "train_pct = dataset_paremeters['train_pct']\n",
    "test_pct = dataset_paremeters['test_pct']\n",
    "\n",
    "\n",
    "#> Training Parameters\n",
    "training_parameters = hyper_parameters['training_parameters']\n",
    "batch_size = training_parameters['batch_size']\n",
    "epochs = training_parameters['epochs']\n",
    "learning_rate = training_parameters['learning_rate']\n",
    "shuffle = training_parameters['shuffle']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de1fed0",
   "metadata": {},
   "source": [
    "# Selecting Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bef9e826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 20 23:50:21 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.02                 Driver Version: 576.02         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| 56%   36C    P0             20W /   75W |    1290MiB /   4096MiB |     22%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A             852    C+G   ...h_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A            1204    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A            1280    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A            3208    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A            7244    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A            7280    C+G   ...we\\Microsoft.Media.Player.exe      N/A      |\n",
      "|    0   N/A  N/A            7956    C+G   ...ms\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A            8272    C+G   ...\\app-3.4.19\\GitHubDesktop.exe      N/A      |\n",
      "|    0   N/A  N/A           10108    C+G   ...4__8wekyb3d8bbwe\\Video.UI.exe      N/A      |\n",
      "|    0   N/A  N/A           10152    C+G   ...h_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A           12132    C+G   ...cord\\app-1.0.9191\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A           12232    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           13896    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A           14552    C+G   ....0.3240.76\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           14840    C+G   ...ekyb3d8bbwe\\CalculatorApp.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0488c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce GTX 1650\n",
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "print(\"Current device:\", torch.cuda.current_device() if torch.cuda.is_available() else \"CPU\")\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Check if CUDA device 2 is available\n",
    "    if torch.cuda.device_count() > 2:\n",
    "        device = torch.device(\"cuda:2\")\n",
    "        torch.cuda.set_device(device)\n",
    "    else:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        torch.cuda.set_device(device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4641a722",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83129be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files: 100%|██████████| 165/165 [00:06<00:00, 26.96file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading!\n",
      "Length of dataset: 9301\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_bundler = DataBundler()\n",
    "number_of_top_frequiences = 10\n",
    "\n",
    "print(\"Training Data\")\n",
    "training_data, training_filenames, training_clip_lengths = data_bundler.load_dataset(inclusion_string=train_data_inclusion_string, include_supplemental=True, percentage=train_pct)\n",
    "number_of_training_data = len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a570a03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-30.613369, -46.15013 , -36.013493, ..., -77.4834  , -79.75581 ,\n",
       "        -79.92505 ],\n",
       "       [-46.366432, -38.843964, -39.360756, ..., -80.      , -79.2138  ,\n",
       "        -77.76479 ],\n",
       "       [-30.10522 , -32.62672 , -35.006634, ..., -78.29423 , -80.      ,\n",
       "        -80.      ],\n",
       "       ...,\n",
       "       [-33.13179 , -37.08852 , -33.435696, ..., -65.2826  , -66.565346,\n",
       "        -68.15612 ],\n",
       "       [-40.648003, -36.418545, -32.35973 , ..., -68.0149  , -64.01764 ,\n",
       "        -67.17018 ],\n",
       "       [-33.20739 , -29.357014, -34.32784 , ..., -67.48633 , -66.235374,\n",
       "        -67.68035 ]], shape=(9301, 640), dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.BaselineAutoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "training_dataset = torch.tensor(training_data, dtype=torch.float32)\n",
    "training_input_features = DataLoader(training_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd1c2720",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_losses = []\n",
    "\n",
    "def train_model():\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for data in training_input_features:\n",
    "            input = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(input)\n",
    "            loss = criterion(output, input)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(training_input_features)\n",
    "        training_losses.append(avg_loss)\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}] ({elapsed_time:.2f}s) | Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5a2297a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] (1.97s) | Loss: 1121.7184\n",
      "Epoch [2/10] (2.18s) | Loss: 926.2248\n",
      "Epoch [3/10] (2.40s) | Loss: 737.2110\n",
      "Epoch [4/10] (2.62s) | Loss: 565.6959\n",
      "Epoch [5/10] (2.84s) | Loss: 421.2748\n",
      "Epoch [6/10] (3.06s) | Loss: 300.2661\n",
      "Epoch [7/10] (3.27s) | Loss: 206.1676\n",
      "Epoch [8/10] (3.49s) | Loss: 142.7423\n",
      "Epoch [9/10] (3.72s) | Loss: 100.4289\n",
      "Epoch [10/10] (3.93s) | Loss: 71.9572\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9297ea5c",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f561dda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files: 100%|██████████| 29/29 [00:01<00:00, 28.80file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading!\n",
      "Length of dataset: 1826\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_bundler = DataBundler()\n",
    "number_of_top_frequiences = 10\n",
    "\n",
    "print(\"Testing Data\")\n",
    "testing_data, testing_filenames, testing_clip_lengths = data_bundler.load_dataset(inclusion_string=test_data_inclusion_string, include_supplemental=True, percentage=test_pct)\n",
    "number_of_testing_data = len(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f88a4b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_testing_data = torch.tensor(testing_data, dtype=torch.float32)\n",
    "testing_input_features = DataLoader(tensor_testing_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92ecb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma PDF: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.01024898 0.01169544 0.01261263 0.01329107 0.0138299  0.01427592\n",
      " 0.01465521 0.01498392 0.01527283 0.01552948 0.01575939 0.01596673\n",
      " 0.01615474 0.01632599 0.01648253 0.01662606 0.016758   0.01687953\n",
      " 0.01699165 0.01709523 0.01719101 0.01727965 0.01736172 0.01743771\n",
      " 0.01750808 0.01757323 0.01763351 0.01768924 0.01774071 0.01778819\n",
      " 0.01783191 0.0178721  0.01790896 0.01794266 0.01797338 0.01800128\n",
      " 0.01802649 0.01804916 0.01806941 0.01808735 0.0181031  0.01811674\n",
      " 0.01812839 0.01813812 0.01814602 0.01815217 0.01815665 0.01815951\n",
      " 0.01816083 0.01816067 0.01815909 0.01815614 0.01815188 0.01814635\n",
      " 0.01813961 0.0181317  0.01812266 0.01811253 0.01810135 0.01808917\n",
      " 0.01807601 0.0180619  0.01804689 0.01803101 0.01801427 0.01799672\n",
      " 0.01797838 0.01795927 0.01793943 0.01791887 0.01789761 0.01787569\n",
      " 0.01785312 0.01782993 0.01780613 0.01778174 0.01775678 0.01773127\n",
      " 0.01770523 0.01767868 0.01765162 0.01762408 0.01759607 0.01756761\n",
      " 0.0175387  0.01750937 0.01747962 0.01744948 0.01741894 0.01738803\n",
      " 0.01735675 0.01732513 0.01729315 0.01726085 0.01722823 0.01719529\n",
      " 0.01716206 0.01712853 0.01709472 0.01706063 0.01702628 0.01699167\n",
      " 0.01695681 0.01692172 0.01688639 0.01685083 0.01681506 0.01677907\n",
      " 0.01674288 0.0167065  0.01666992 0.01663316 0.01659622 0.01655911\n",
      " 0.01652184 0.0164844  0.01644681 0.01640907 0.01637119 0.01633317\n",
      " 0.01629501 0.01625673 0.01621832 0.0161798  0.01614116 0.01610241\n",
      " 0.01606356 0.0160246  0.01598555 0.01594641 0.01590718 0.01586786\n",
      " 0.01582847 0.015789   0.01574945 0.01570983 0.01567015 0.01563041\n",
      " 0.0155906  0.01555074 0.01551083 0.01547087 0.01543086 0.0153908\n",
      " 0.01535071 0.01531057 0.01527041 0.0152302  0.01518997 0.01514972\n",
      " 0.01510943 0.01506913 0.0150288  0.01498846 0.0149481  0.01490773\n",
      " 0.01486735 0.01482696 0.01478657 0.01474617 0.01470577 0.01466537\n",
      " 0.01462497 0.01458457 0.01454418 0.0145038  0.01446343 0.01442307\n",
      " 0.01438272 0.01434238 0.01430206 0.01426177 0.01422148 0.01418123\n",
      " 0.01414099 0.01410077 0.01406059 0.01402043 0.01398029 0.01394019\n",
      " 0.01390012 0.01386008 0.01382008 0.01378011 0.01374017 0.01370028\n",
      " 0.01366042 0.0136206  0.01358082 0.01354108 0.01350139 0.01346174\n",
      " 0.01342214 0.01338258 0.01334307 0.01330361 0.0132642  0.01322484\n",
      " 0.01318552 0.01314626 0.01310706 0.0130679  0.01302881 0.01298976\n",
      " 0.01295077 0.01291184 0.01287297 0.01283416 0.0127954  0.0127567\n",
      " 0.01271807 0.0126795  0.01264099 0.01260254 0.01256415 0.01252583\n",
      " 0.01248757 0.01244938 0.01241125 0.01237319 0.0123352  0.01229727\n",
      " 0.01225941 0.01222162 0.0121839  0.01214625 0.01210867 0.01207116\n",
      " 0.01203372 0.01199635 0.01195905 0.01192183 0.01188467 0.0118476\n",
      " 0.01181059 0.01177366 0.0117368  0.01170002 0.01166331 0.01162668\n",
      " 0.01159012 0.01155364 0.01151724 0.01148091 0.01144466 0.01140849\n",
      " 0.01137239 0.01133637 0.01130043 0.01126457 0.01122878 0.01119308\n",
      " 0.01115745 0.01112191 0.01108644 0.01105106 0.01101575 0.01098053\n",
      " 0.01094538 0.01091031 0.01087533 0.01084043 0.01080561 0.01077087\n",
      " 0.01073621 0.01070163 0.01066714 0.01063272 0.01059839 0.01056414\n",
      " 0.01052998 0.01049589 0.01046189 0.01042797 0.01039414 0.01036038\n",
      " 0.01032671 0.01029313 0.01025963 0.0102262  0.01019287 0.01015961\n",
      " 0.01012645 0.01009336 0.01006036 0.01002744 0.00999461 0.00996186\n",
      " 0.00992919 0.00989661 0.00986411 0.00983169 0.00979936 0.00976711\n",
      " 0.00973495 0.00970287 0.00967088 0.00963897 0.00960714 0.0095754\n",
      " 0.00954374 0.00951217 0.00948068 0.00944927 0.00941795 0.00938671\n",
      " 0.00935556 0.00932449 0.0092935  0.0092626  0.00923178 0.00920105\n",
      " 0.0091704  0.00913984 0.00910935 0.00907896 0.00904864 0.00901841\n",
      " 0.00898826 0.0089582  0.00892822 0.00889832 0.00886851 0.00883878\n",
      " 0.00880913 0.00877957 0.00875009 0.00872069 0.00869137 0.00866214\n",
      " 0.00863299 0.00860393 0.00857494 0.00854604 0.00851722 0.00848849\n",
      " 0.00845983 0.00843126 0.00840277 0.00837436 0.00834604 0.00831779\n",
      " 0.00828963 0.00826155 0.00823355 0.00820564 0.0081778  0.00815004\n",
      " 0.00812237 0.00809478 0.00806726 0.00803983 0.00801248 0.00798521\n",
      " 0.00795802 0.00793091 0.00790388 0.00787693 0.00785006 0.00782327\n",
      " 0.00779656 0.00776993 0.00774338 0.00771691 0.00769051 0.0076642\n",
      " 0.00763796 0.00761181 0.00758573 0.00755973 0.00753381 0.00750797\n",
      " 0.0074822  0.00745651 0.00743091 0.00740537 0.00737992 0.00735454\n",
      " 0.00732925 0.00730402 0.00727888 0.00725381 0.00722882 0.0072039\n",
      " 0.00717906 0.0071543  0.00712961 0.007105   0.00708047 0.00705601\n",
      " 0.00703162 0.00700732 0.00698308 0.00695892 0.00693484 0.00691083\n",
      " 0.0068869  0.00686303 0.00683925 0.00681554 0.0067919  0.00676833\n",
      " 0.00674484 0.00672143 0.00669808 0.00667481 0.00665161 0.00662849\n",
      " 0.00660544 0.00658246 0.00655955 0.00653671 0.00651395 0.00649126\n",
      " 0.00646864 0.00644609 0.00642361 0.00640121 0.00637887 0.00635661\n",
      " 0.00633441 0.00631229 0.00629024 0.00626826 0.00624634 0.0062245\n",
      " 0.00620273 0.00618102 0.00615939 0.00613782 0.00611633 0.0060949\n",
      " 0.00607354 0.00605225 0.00603103 0.00600988 0.00598879 0.00596778\n",
      " 0.00594683 0.00592594 0.00590513 0.00588438 0.0058637  0.00584309\n",
      " 0.00582254 0.00580206 0.00578165 0.0057613  0.00574102 0.0057208\n",
      " 0.00570065 0.00568057 0.00566055 0.00564059 0.0056207  0.00560088\n",
      " 0.00558112 0.00556142 0.00554179 0.00552222 0.00550272 0.00548328\n",
      " 0.00546391 0.0054446  0.00542535 0.00540616 0.00538704 0.00536798\n",
      " 0.00534898 0.00533005 0.00531118 0.00529237 0.00527362 0.00525493\n",
      " 0.00523631 0.00521774 0.00519924 0.0051808  0.00516242 0.0051441\n",
      " 0.00512585 0.00510765 0.00508951 0.00507143 0.00505342 0.00503546\n",
      " 0.00501756 0.00499972 0.00498194 0.00496422 0.00494656 0.00492896\n",
      " 0.00491142 0.00489393 0.00487651 0.00485914 0.00484183 0.00482458\n",
      " 0.00480738 0.00479024 0.00477316 0.00475614 0.00473918 0.00472227\n",
      " 0.00470542 0.00468862 0.00467188 0.0046552  0.00463857 0.004622\n",
      " 0.00460548 0.00458903 0.00457262 0.00455627 0.00453998 0.00452374\n",
      " 0.00450756 0.00449142 0.00447535 0.00445933 0.00444336 0.00442745\n",
      " 0.00441159 0.00439579 0.00438003 0.00436434 0.00434869 0.0043331\n",
      " 0.00431756 0.00430207 0.00428664 0.00427126 0.00425593 0.00424065\n",
      " 0.00422542 0.00421025 0.00419513 0.00418006 0.00416504 0.00415007\n",
      " 0.00413515 0.00412029 0.00410547 0.00409071 0.00407599 0.00406133\n",
      " 0.00404672 0.00403215 0.00401764 0.00400317 0.00398876 0.00397439\n",
      " 0.00396007 0.00394581 0.00393159 0.00391742 0.0039033  0.00388922\n",
      " 0.0038752  0.00386122 0.00384729 0.00383341 0.00381958 0.0038058\n",
      " 0.00379206 0.00377837 0.00376472 0.00375113 0.00373758 0.00372408\n",
      " 0.00371062 0.00369721 0.00368385 0.00367053 0.00365726 0.00364403\n",
      " 0.00363085 0.00361771 0.00360463 0.00359158 0.00357858 0.00356563\n",
      " 0.00355272 0.00353986 0.00352704 0.00351426 0.00350153 0.00348884\n",
      " 0.0034762  0.0034636  0.00345105 0.00343853 0.00342607 0.00341364\n",
      " 0.00340126 0.00338892 0.00337662 0.00336437 0.00335216 0.00333999\n",
      " 0.00332787 0.00331578 0.00330374 0.00329174 0.00327979 0.00326787\n",
      " 0.003256   0.00324416 0.00323237 0.00322062 0.00320891 0.00319724\n",
      " 0.00318562 0.00317403 0.00316248 0.00315097 0.00313951 0.00312808\n",
      " 0.0031167  0.00310535 0.00309405 0.00308278 0.00307155 0.00306036\n",
      " 0.00304921 0.00303811 0.00302703 0.003016   0.00300501 0.00299406\n",
      " 0.00298314 0.00297226 0.00296142 0.00295062 0.00293986 0.00292913\n",
      " 0.00291844 0.00290779 0.00289718 0.00288661 0.00287607 0.00286557\n",
      " 0.0028551  0.00284468 0.00283428 0.00282393 0.00281361 0.00280333\n",
      " 0.00279309 0.00278288 0.00277271 0.00276257 0.00275247 0.0027424\n",
      " 0.00273238 0.00272238 0.00271242 0.0027025  0.00269261 0.00268276\n",
      " 0.00267294 0.00266315 0.0026534  0.00264369 0.00263401 0.00262436\n",
      " 0.00261475 0.00260517 0.00259563 0.00258612 0.00257664 0.0025672\n",
      " 0.00255779 0.00254841 0.00253907 0.00252976 0.00252049 0.00251124\n",
      " 0.00250203 0.00249285 0.00248371 0.0024746  0.00246552 0.00245647\n",
      " 0.00244745 0.00243847 0.00242952 0.0024206  0.00241171 0.00240285\n",
      " 0.00239403 0.00238523 0.00237647 0.00236774 0.00235904 0.00235037\n",
      " 0.00234173 0.00233312 0.00232455 0.002316   0.00230749 0.002299\n",
      " 0.00229055 0.00228212 0.00227373 0.00226536 0.00225703 0.00224872\n",
      " 0.00224045 0.0022322  0.00222399 0.0022158  0.00220764 0.00219951\n",
      " 0.00219141 0.00218334 0.0021753  0.00216729 0.00215931 0.00215135\n",
      " 0.00214343 0.00213553 0.00212766 0.00211982 0.002112   0.00210422\n",
      " 0.00209646 0.00208873 0.00208103 0.00207335 0.00206571 0.00205809\n",
      " 0.00205049 0.00204293 0.00203539 0.00202788 0.0020204  0.00201294\n",
      " 0.00200551 0.00199811 0.00199073 0.00198338 0.00197606 0.00196876\n",
      " 0.00196149 0.00195424 0.00194702 0.00193983 0.00193266 0.00192552\n",
      " 0.00191841 0.00191132 0.00190425 0.00189721 0.0018902  0.00188321\n",
      " 0.00187625 0.00186931 0.0018624  0.00185551 0.00184865 0.00184181\n",
      " 0.001835   0.00182821 0.00182144 0.0018147  0.00180799 0.0018013\n",
      " 0.00179463 0.00178798 0.00178137 0.00177477]\n",
      "Anomaly Threshold: 126.47988809624925\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator()\n",
    "\n",
    "original_clips = evaluator.bundle(testing_data, testing_clip_lengths)\n",
    "reconstructed_clips = evaluator.get_output(model, testing_input_features, testing_clip_lengths, device)\n",
    "\n",
    "reconstruction_errors = evaluator.reconstruction_error(original_clips, reconstructed_clips)\n",
    "\n",
    "gamma_pdf, anomaly_threshold = evaluator.gamma_distribution(reconstruction_errors)\n",
    "#true_labels, predicted_labels, anomaly_scores = evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c06b80f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
